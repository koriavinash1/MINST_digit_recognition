{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import input_data\n",
    "from additional_funcs import unroll_image\n",
    "mnist = input_data.read_data_sets(one_hot = True, train_image_number = 60, test_image_number = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "display_step = 1\n",
    "epoch = 1\n",
    "batch_size = 1\n",
    "categories = 10\n",
    "periodicity = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 784 \n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "\n",
    "image_real = tf.placeholder(dtype = tf.float32, shape = (None, n_inputs), name = \"real_input\")\n",
    "image_imag = tf.placeholder(dtype = tf.float32, shape = (None, n_inputs), name = \"imaginary_input\")\n",
    "label_real = tf.placeholder(dtype = tf.float32, shape = (None,n_classes), name = \"expected_output_real\")\n",
    "label_imag = tf.placeholder(dtype = tf.float32, shape = (None,n_classes), name = \"expected_output_imag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# miscill... functions\n",
    "\n",
    "def activation(input_data, weights, biases):\n",
    "    real = tf.add(tf.subtract(tf.matmul(input_data['real'], weights['real']), tf.matmul(input_data['imaginary'], weights['imaginary'])), biases['real'])\n",
    "    imag = tf.add(tf.add(tf.matmul(input_data['real'], weights['imaginary']), tf.matmul(input_data['imaginary'], weights['real'])), biases['imaginary'])\n",
    "    return {'real':real, 'imaginary': imag}\n",
    "\n",
    "def nonlinear(activated_layer):\n",
    "    real = tf.nn.relu(activated_layer['real'])\n",
    "    imag = tf.nn.relu(activated_layer['imaginary'])\n",
    "    return {'real': real, 'imaginary': imag}\n",
    "\n",
    "def z2class(out):\n",
    "#     angle = tf.cond(out['real']!=0, lambda: tf.divide(out['imaginary'], out['real']), lambda: 1)\n",
    "    angle = tf.atan(tf.divide(out['imaginary'], out['real']+0.001))\n",
    "    angle = tf.mod(tf.add(angle, 2*3.141), 2*3.141)\n",
    "    return {'real':tf.cos(angle), 'imaginary':tf.sin(angle)}\n",
    "\n",
    "def class2z(batch_y):\n",
    "    angle = tf.dot(tf.add(batch_y, 0.5), tf.dot(tf.range(categories), periodicity * 2 * 3.14))\n",
    "    return {'real': tf.cos(angle), 'imaginary':tf.sin(angle)}\n",
    "\n",
    "def define_variable(shape, name):\n",
    "    return tf.Variable(tf.truncated_normal(shape = shape, name = name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_real = {\n",
    "    'wih1': define_variable([n_inputs, 32], 'wr1'),\n",
    "    'wh1h2': define_variable([32, 64], 'wr2'),\n",
    "    'wh2h3': define_variable([64, 1024], 'wr3'),\n",
    "    'wh3h4': define_variable([1024, 1024], 'wr4'),\n",
    "    'wh4o': define_variable([1024, n_classes], 'wr5'),\n",
    "}\n",
    "\n",
    "weights_imaginary ={\n",
    "    'wih1': define_variable([n_inputs, 32], 'wi1'),\n",
    "    'wh1h2': define_variable([32, 64], 'wi2'),\n",
    "    'wh2h3': define_variable([64, 1024], 'wi3'),\n",
    "    'wh3h4': define_variable([1024, 1024], 'wi4'),\n",
    "    'wh4o': define_variable([1024, n_classes], 'wi5'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases_real = {\n",
    "    'bih1': define_variable([32], 'br1'),\n",
    "    'bh1h2': define_variable([64], 'br2'),\n",
    "    'bh2h3': define_variable([1024], 'br3'),\n",
    "    'bh3h4': define_variable([1024], 'br4'),\n",
    "    'bh4o': define_variable([n_classes], 'br5'),\n",
    "}\n",
    "\n",
    "biases_imaginary = {\n",
    "    'bih1': define_variable([32], 'bi1'),\n",
    "    'bh1h2': define_variable([64], 'bi2'),\n",
    "    'bh2h3': define_variable([1024], 'bi3'),\n",
    "    'bh3h4': define_variable([1024], 'bi4'),\n",
    "    'bh4o': define_variable([n_classes], 'bi5'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main graph\n",
    "\n",
    "def main_network(x, weights, biases):\n",
    "    fc1 = activation(x, {'real':weights_real['wih1'], 'imaginary': weights_imaginary['wih1']}, {'real':biases_real['bih1'], 'imaginary': biases_imaginary['bih1']})\n",
    "    fc1 = nonlinear(fc1)\n",
    "    \n",
    "    fc2 = activation(fc1, {'real':weights_real['wh1h2'], 'imaginary': weights_imaginary['wh1h2']}, {'real':biases_real['bh1h2'], 'imaginary': biases_imaginary['bh1h2']})\n",
    "    fc2 = nonlinear(fc2)\n",
    "    \n",
    "    fc3 = activation(fc2, {'real':weights_real['wh2h3'], 'imaginary': weights_imaginary['wh2h3']}, {'real':biases_real['bh2h3'], 'imaginary': biases_imaginary['bh2h3']})\n",
    "    fc3 = nonlinear(fc3)\n",
    "    \n",
    "    fc4 = activation(fc3, {'real':weights_real['wh3h4'], 'imaginary': weights_imaginary['wh3h4']}, {'real':biases_real['bh3h4'], 'imaginary': biases_imaginary['bh3h4']})\n",
    "    fc4 = nonlinear(fc4)\n",
    "    \n",
    "    out = activation(fc4, {'real':weights_real['wh4o'], 'imaginary': weights_imaginary['wh4o']}, {'real':biases_real['bh4o'], 'imaginary': biases_imaginary['bh4o']})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "No gradient defined for operation 'Mod_8' (op type: Mod)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-d455ea518396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# optimizer for real and imaginary components of loss function...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mreal_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cost\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimaginary_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mimaginary_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimaginary_cost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreal_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    457\u001b[0m               raise LookupError(\n\u001b[1;32m    458\u001b[0m                   \u001b[0;34m\"No gradient defined for operation '%s' (op type: %s)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                   (op.name, op.type))\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m           \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnterGradWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: No gradient defined for operation 'Mod_8' (op type: Mod)"
     ]
    }
   ],
   "source": [
    "prediction = main_network({'real':image_real, 'imaginary': image_imag}, {'real':weights_real, 'imaginary':weights_imaginary}, {'real':biases_real, 'imaginary':biases_imaginary})\n",
    "prediction = z2class(prediction)\n",
    "\n",
    "# define real and imaginary components of loss function...\n",
    "real_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction['real'], labels = label_real))\n",
    "imaginary_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction['imaginary'], labels = label_imag))\n",
    "\n",
    "#net cost is peoduct of both\n",
    "cost = real_cost * imaginary_cost\n",
    "\n",
    "# optimizer for real and imaginary components of loss function...\n",
    "real_optimizer = tf.train.AdamOptimizer(learning_rate).minimize((real_cost - imaginary_cost))\n",
    "imaginary_optimizer = tf.train.AdamOptimizer(learning_rate).minimize((imaginary_cost + real_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model evaluation correct real and imaginary prediction ..\n",
    "correct_real_prediction = tf.equal(tf.argmax(prediction['real'], 1), tf.argmax(label_real, 1))\n",
    "correct_imaginary_prediction = tf.equal(tf.argmax(prediction['imaginary'], 1), tf.argmax(label_imag, 1))\n",
    "\n",
    "# real and imaginary accuracy components...\n",
    "real_acc = tf.reduce_mean(tf.cast(correct_real_prediction, tf.float32))\n",
    "imag_acc = tf.reduce_mean(tf.cast(correct_imaginary_prediction, tf.float32))\n",
    "\n",
    "# final accuracy is product of both real and imaginary components.. \n",
    "accuracy = real_acc * imag_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all tf variable initialization ...\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/build/buildd/opencv-2.4.8+dfsg1/modules/imgproc/src/color.cpp:3642: error: (-215) depth == CV_8U || depth == CV_16U || depth == CV_32F in function cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-a4cdbeb0d6de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Calculate accuracy for 256 mnist test images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimage_real\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munroll_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_real\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass2z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_imag\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munroll_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_imag\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass2z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/koriavinash/Documents/MNIST_digit_recognition/additional_funcs.py\u001b[0m in \u001b[0;36munroll_image\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mreshapeImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mbinaryImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrey2binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshapeImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# cv2.imshow(\"test\", binaryImage)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m# cv2.waitKey(800)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/koriavinash/Documents/MNIST_digit_recognition/additional_funcs.py\u001b[0m in \u001b[0;36mgrey2binary\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrey2binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /build/buildd/opencv-2.4.8+dfsg1/modules/imgproc/src/color.cpp:3642: error: (-215) depth == CV_8U || depth == CV_16U || depth == CV_32F in function cvtColor\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step < epoch:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x, batch_y = unroll_image(batch_x), class2z(batch_y)\n",
    "        \n",
    "        sess.run([real_optimizer, imaginary_optimizer], feed_dict={image_real: tf.cast(tf.real(batch_x), dtype=tf.float32), label_real: tf.cast(tf.real(batch_y), dtype = tf.float32), image_imag: tf.cast(tf.imag(batch_x), dtype=tf.float32), label_imag: tf.cast(tf.imag(batch_y), dtype = tf.float32)})\n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={image_real: tf.cast(tf.real(batch_x), dtype=tf.float32), label_real: tf.cast(tf.real(batch_y), dtype = tf.float32), image_imag: tf.cast(tf.imag(batch_x), dtype=tf.float32), label_imag: tf.cast(tf.imag(batch_y), dtype = tf.float32)})\n",
    "            print(\"loss= {:.6f}\".format(loss) + \", Accuracy= {:.5f}\".format(acc))\n",
    "        step += 1\n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={image_real: tf.cast(tf.real(unroll_image(mnist.test.images[:256])), dtype=tf.float32), label_real: tf.cast(tf.real(class2z(mnist.test.labels[:256])), dtype = tf.float32), image_imag: tf.cast(tf.imag(unroll_image(mnist.test.images[:256])), dtype=tf.float32), label_imag: tf.cast(class2z(tf.imag(mnist.test.labels[:256])), dtype = tf.float32)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
