{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow library\n",
    "import tensorflow as tf\n",
    "import time\n",
    "# Import MNIST data\n",
    "import input_data\n",
    "# one_hot key implies lables in onehot encoding\n",
    "mnist = input_data.read_data_sets(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 128\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = 784 # 28*28\n",
    "n_classes = 10 # (0-9 digits)\n",
    "dropout = 0.75 # What use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, None))\n",
    "y = tf.placeholder(tf.float32, shape=(None, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# miscill... functions\n",
    "def define_variable(shape, name): \n",
    "    return tf.Variable(tf.truncated_normal(shape, name = name))\n",
    "\n",
    "def conv2d(x, W, b):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': define_variable([5, 5, 1, 32], 'wc1'), # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc2': define_variable([5, 5, 32, 64], 'wc2'), # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wfc1': define_variable([7*7*64, 2048], 'wfc1'), # fully connected, 7*7*64 inputs, 2048 outputs\n",
    "    'wfc2': define_variable([2048, 1024], 'wfc2'), # fully connected, 2048 inputs, 1024 outputs\n",
    "    'out': define_variable([1024, n_classes], 'out') # 1024 inputs, 10 outputs (class prediction)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'bc1': define_variable([32], 'bc1'),\n",
    "    'bc2': define_variable([64], 'bc2'),\n",
    "    'bfc1': define_variable([2048], 'bfc1'),\n",
    "    'bfc2': define_variable([1024], 'bfc2'),\n",
    "    'out': define_variable([n_classes], 'out')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_net(x, weights, biases, dropout = dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    \n",
    "    print conv2\n",
    "    \n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wfc1'].get_shape().as_list()[0]])\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wfc1']), biases['bfc1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # fully connected layer 2\n",
    "    fc2 = tf.add(tf.matmul(fc1, weights['wfc2']), biases['bfc2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_5:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "pred = main_net(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 146229.562500, Accuracy= 0.56250\n",
      "loss= 123920.000000, Accuracy= 0.64844\n",
      "loss= 81522.578125, Accuracy= 0.78906\n",
      "loss= 45299.027344, Accuracy= 0.82031\n",
      "loss= 21138.351562, Accuracy= 0.89844\n",
      "loss= 79485.054688, Accuracy= 0.81250\n",
      "loss= 42034.000000, Accuracy= 0.89844\n",
      "loss= 41988.906250, Accuracy= 0.82031\n",
      "loss= 19531.201172, Accuracy= 0.92188\n",
      "loss= 26870.017578, Accuracy= 0.88281\n",
      "loss= 15837.408203, Accuracy= 0.92188\n",
      "loss= 15245.060547, Accuracy= 0.91406\n",
      "loss= 28790.107422, Accuracy= 0.90625\n",
      "loss= 21535.716797, Accuracy= 0.89844\n",
      "loss= 14659.312500, Accuracy= 0.92969\n",
      "loss= 2032.607178, Accuracy= 0.97656\n",
      "loss= 42799.578125, Accuracy= 0.84375\n",
      "loss= 3138.576904, Accuracy= 0.95312\n",
      "loss= 14215.617188, Accuracy= 0.89844\n",
      "loss= 11506.794922, Accuracy= 0.90625\n",
      "loss= 8784.748047, Accuracy= 0.93750\n",
      "loss= 16157.862305, Accuracy= 0.91406\n",
      "loss= 12219.294922, Accuracy= 0.93750\n",
      "loss= 15955.295898, Accuracy= 0.92969\n",
      "loss= 12989.716797, Accuracy= 0.92188\n",
      "loss= 15987.529297, Accuracy= 0.90625\n",
      "loss= 8695.708984, Accuracy= 0.93750\n",
      "loss= 15523.626953, Accuracy= 0.92969\n",
      "loss= 10848.466797, Accuracy= 0.93750\n",
      "loss= 9339.211914, Accuracy= 0.92969\n",
      "loss= 4707.367676, Accuracy= 0.96875\n",
      "loss= 15896.539062, Accuracy= 0.94531\n",
      "loss= 2346.798340, Accuracy= 0.96875\n",
      "loss= 2954.325439, Accuracy= 0.97656\n",
      "loss= 3362.204590, Accuracy= 0.96875\n",
      "loss= 11383.987305, Accuracy= 0.94531\n",
      "loss= 10853.531250, Accuracy= 0.90625\n",
      "loss= 17124.441406, Accuracy= 0.92969\n",
      "loss= 11692.771484, Accuracy= 0.90625\n",
      "loss= 5579.809570, Accuracy= 0.96094\n",
      "loss= 12585.615234, Accuracy= 0.95312\n",
      "loss= 1535.450684, Accuracy= 0.98438\n",
      "loss= 6329.337891, Accuracy= 0.93750\n",
      "loss= 6014.777344, Accuracy= 0.96875\n",
      "loss= 3411.141602, Accuracy= 0.96094\n",
      "loss= 7187.991699, Accuracy= 0.94531\n",
      "loss= 2882.121826, Accuracy= 0.98438\n",
      "loss= 6767.492676, Accuracy= 0.95312\n",
      "loss= 4809.829590, Accuracy= 0.96094\n",
      "loss= 486.673828, Accuracy= 0.99219\n",
      "loss= 2788.259277, Accuracy= 0.97656\n",
      "loss= 13377.577148, Accuracy= 0.90625\n",
      "loss= 2417.126465, Accuracy= 0.97656\n",
      "loss= 2954.335449, Accuracy= 0.97656\n",
      "loss= 4595.478516, Accuracy= 0.96875\n",
      "loss= 4875.031250, Accuracy= 0.96875\n",
      "loss= 5523.600586, Accuracy= 0.95312\n",
      "loss= 7016.290039, Accuracy= 0.93750\n",
      "loss= 3827.904297, Accuracy= 0.97656\n",
      "loss= 3682.787109, Accuracy= 0.97656\n",
      "loss= 9885.353516, Accuracy= 0.96094\n",
      "loss= 940.985168, Accuracy= 0.97656\n",
      "loss= 10055.385742, Accuracy= 0.93750\n",
      "loss= 9866.048828, Accuracy= 0.94531\n",
      "loss= 6315.095215, Accuracy= 0.96094\n",
      "loss= 5115.495117, Accuracy= 0.95312\n",
      "loss= 2685.048828, Accuracy= 0.97656\n",
      "loss= 6456.924805, Accuracy= 0.96875\n",
      "loss= 9632.320312, Accuracy= 0.97656\n",
      "loss= 260.391052, Accuracy= 0.98438\n",
      "loss= 13193.531250, Accuracy= 0.96094\n",
      "loss= 404.069214, Accuracy= 0.96875\n",
      "loss= 1531.402832, Accuracy= 0.99219\n",
      "loss= 6392.437012, Accuracy= 0.97656\n",
      "loss= 766.850586, Accuracy= 0.99219\n",
      "loss= 11170.335938, Accuracy= 0.94531\n",
      "loss= 1869.432251, Accuracy= 0.97656\n",
      "loss= 2834.054199, Accuracy= 0.96875\n",
      "loss= 5595.446289, Accuracy= 0.94531\n",
      "loss= 5178.242188, Accuracy= 0.96875\n",
      "loss= 2615.922607, Accuracy= 0.97656\n",
      "loss= 8200.971680, Accuracy= 0.95312\n",
      "loss= 1370.889648, Accuracy= 0.96875\n",
      "loss= 1650.554688, Accuracy= 0.97656\n",
      "loss= 9485.574219, Accuracy= 0.96094\n",
      "loss= 3766.244629, Accuracy= 0.96875\n",
      "loss= 2329.158691, Accuracy= 0.96875\n",
      "loss= 4385.526367, Accuracy= 0.96875\n",
      "loss= 833.673340, Accuracy= 0.99219\n",
      "loss= 4436.279297, Accuracy= 0.95312\n",
      "loss= 1682.784668, Accuracy= 0.98438\n",
      "loss= 775.331299, Accuracy= 0.97656\n",
      "loss= 5672.858398, Accuracy= 0.96875\n",
      "loss= 381.309448, Accuracy= 0.98438\n",
      "loss= 337.145508, Accuracy= 0.99219\n",
      "loss= 3198.084961, Accuracy= 0.98438\n",
      "loss= 0.000000, Accuracy= 1.00000\n",
      "loss= 5450.516602, Accuracy= 0.94531\n",
      "loss= 2976.028320, Accuracy= 0.97656\n",
      "loss= 2678.354248, Accuracy= 0.96875\n",
      "loss= 0.000000, Accuracy= 1.00000\n",
      "loss= 6464.679199, Accuracy= 0.96875\n",
      "loss= 0.000000, Accuracy= 1.00000\n",
      "loss= 2220.151367, Accuracy= 0.97656\n",
      "loss= 5343.525391, Accuracy= 0.94531\n",
      "loss= 1322.789917, Accuracy= 0.98438\n",
      "loss= 4222.871094, Accuracy= 0.98438\n",
      "loss= 4440.092285, Accuracy= 0.97656\n",
      "loss= 3679.227783, Accuracy= 0.96094\n",
      "loss= 2666.167969, Accuracy= 0.97656\n",
      "loss= 2563.634766, Accuracy= 0.97656\n",
      "loss= 3869.782471, Accuracy= 0.96875\n",
      "loss= 5065.846680, Accuracy= 0.96094\n",
      "loss= 859.183350, Accuracy= 0.99219\n",
      "loss= 3191.695801, Accuracy= 0.97656\n",
      "loss= 2284.518311, Accuracy= 0.98438\n",
      "loss= 9178.020508, Accuracy= 0.93750\n",
      "loss= 4581.447266, Accuracy= 0.96094\n",
      "loss= 2387.993164, Accuracy= 0.97656\n",
      "loss= 4840.815430, Accuracy= 0.96875\n",
      "loss= 691.503784, Accuracy= 0.98438\n",
      "loss= 827.617432, Accuracy= 0.99219\n",
      "loss= 3157.186768, Accuracy= 0.95312\n",
      "loss= 5492.977539, Accuracy= 0.96094\n",
      "loss= 3132.784180, Accuracy= 0.98438\n",
      "loss= 2635.068848, Accuracy= 0.99219\n",
      "loss= 3638.744385, Accuracy= 0.96094\n",
      "loss= 0.000000, Accuracy= 1.00000\n",
      "loss= 5935.021484, Accuracy= 0.96875\n",
      "loss= 4764.238281, Accuracy= 0.97656\n",
      "loss= 1836.872559, Accuracy= 0.98438\n",
      "loss= 3625.324707, Accuracy= 0.96875\n",
      "loss= 1340.322876, Accuracy= 0.99219\n",
      "loss= 714.759033, Accuracy= 0.98438\n",
      "loss= 923.428223, Accuracy= 0.99219\n",
      "loss= 0.000000, Accuracy= 1.00000\n",
      "loss= 150.997314, Accuracy= 0.99219\n",
      "loss= 3576.627197, Accuracy= 0.96875\n",
      "loss= 1651.913086, Accuracy= 0.98438\n",
      "loss= 704.451660, Accuracy= 0.97656\n",
      "loss= 1229.805176, Accuracy= 0.98438\n",
      "loss= 1090.762451, Accuracy= 0.98438\n",
      "loss= 0.000000, Accuracy= 1.00000\n",
      "loss= 4776.951660, Accuracy= 0.96875\n",
      "loss= 1711.157837, Accuracy= 0.97656\n",
      "loss= 762.118408, Accuracy= 0.98438\n",
      "loss= 630.458984, Accuracy= 0.99219\n",
      "loss= 1913.452026, Accuracy= 0.97656\n",
      "loss= 29.382568, Accuracy= 0.99219\n",
      "loss= 1698.517578, Accuracy= 0.98438\n",
      "loss= 28.938477, Accuracy= 0.99219\n",
      "loss= 3691.803711, Accuracy= 0.97656\n",
      "loss= 1001.804443, Accuracy= 0.99219\n",
      "loss= 2354.836182, Accuracy= 0.96875\n",
      "loss= 1378.017334, Accuracy= 0.98438\n",
      "loss= 635.551819, Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "1493702363.12\n",
      "('Testing Accuracy:', 0.99609375)\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    t = time.time()\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"loss= {:.6f}\".format(loss) + \", Accuracy= {:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    print t\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images[:256], y: mnist.test.labels[:256]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
