{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import input_data\n",
    "from additional_funcs import unroll_image\n",
    "mnist = input_data.read_data_sets(one_hot = True, train_image_number = 60, test_image_number = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "display_step = 1\n",
    "epoch = 1\n",
    "batch_size = 10\n",
    "categories = 10\n",
    "periodicity = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 784 \n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholders\n",
    "\n",
    "image_real = tf.placeholder(dtype = tf.float32, shape = (None, n_inputs), name = \"real_input\")\n",
    "image_imag = tf.placeholder(dtype = tf.float32, shape = (None, n_inputs), name = \"imaginary_input\")\n",
    "label_real = tf.placeholder(dtype = tf.float32, shape = (None,n_classes), name = \"expected_output_real\")\n",
    "label_imag = tf.placeholder(dtype = tf.float32, shape = (None,n_classes), name = \"expected_output_imag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# miscill... functions\n",
    "\n",
    "def activation(input_data, weights, biases):\n",
    "    real = tf.add(tf.subtract(tf.matmul(input_data['real'], weights['real']), tf.matmul(input_data['imaginary'], weights['imaginary'])), biases['real'])\n",
    "    imag = tf.add(tf.add(tf.matmul(input_data['real'], weights['imaginary']), tf.matmul(input_data['imaginary'], weights['real'])), biases['imaginary'])\n",
    "    return {'real':real, 'imaginary': imag}\n",
    "\n",
    "def nonlinear(activated_layer):\n",
    "    real = tf.tanh(activated_layer['real'])\n",
    "    imag = tf.tanh(activated_layer['imaginary'])\n",
    "    return {'real': real, 'imaginary': imag}\n",
    "\n",
    "def z2class(out):\n",
    "    # angle = tf.cond(out['real']!=0, lambda: tf.divide(out['imaginary'], out['real']), lambda: 1)\n",
    "    angle = tf.atan(tf.divide(out['imaginary'], out['real']+0.001))\n",
    "    angle = tf.mod(tf.add(angle, 2*3.141), 2*3.141)\n",
    "    return {'real':tf.cos(angle), 'imaginary':tf.sin(angle)}\n",
    "\n",
    "def class2z(batch_y):\n",
    "    angle = tf.dot(tf.add(batch_y, 0.5), tf.dot(tf.range(categories), periodicity * 2 * 3.14))\n",
    "    return {'real': tf.cos(angle), 'imaginary':tf.sin(angle)}\n",
    "\n",
    "def define_variable(shape, name):\n",
    "    return tf.Variable(tf.truncated_normal(shape = shape, name = name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_real = {\n",
    "    'wih1': define_variable([n_inputs, 32], 'wr1'),\n",
    "    'wh1h2': define_variable([32, 64], 'wr2'),\n",
    "    'wh2h3': define_variable([64, 1024], 'wr3'),\n",
    "    'wh3h4': define_variable([1024, 1024], 'wr4'),\n",
    "    'wh4o': define_variable([1024, n_classes], 'wr5'),\n",
    "}\n",
    "\n",
    "weights_imaginary ={\n",
    "    'wih1': define_variable([n_inputs, 32], 'wi1'),\n",
    "    'wh1h2': define_variable([32, 64], 'wi2'),\n",
    "    'wh2h3': define_variable([64, 1024], 'wi3'),\n",
    "    'wh3h4': define_variable([1024, 1024], 'wi4'),\n",
    "    'wh4o': define_variable([1024, n_classes], 'wi5'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases_real = {\n",
    "    'bih1': define_variable([32], 'br1'),\n",
    "    'bh1h2': define_variable([64], 'br2'),\n",
    "    'bh2h3': define_variable([1024], 'br3'),\n",
    "    'bh3h4': define_variable([1024], 'br4'),\n",
    "    'bh4o': define_variable([n_classes], 'br5'),\n",
    "}\n",
    "\n",
    "biases_imaginary = {\n",
    "    'bih1': define_variable([32], 'bi1'),\n",
    "    'bh1h2': define_variable([64], 'bi2'),\n",
    "    'bh2h3': define_variable([1024], 'bi3'),\n",
    "    'bh3h4': define_variable([1024], 'bi4'),\n",
    "    'bh4o': define_variable([n_classes], 'bi5'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main graph\n",
    "\n",
    "def main_network(x, weights, biases):\n",
    "    fc1 = activation(x, {'real':weights_real['wih1'], 'imaginary': weights_imaginary['wih1']}, {'real':biases_real['bih1'], 'imaginary': biases_imaginary['bih1']})\n",
    "    fc1 = nonlinear(fc1)\n",
    "    \n",
    "    fc2 = activation(fc1, {'real':weights_real['wh1h2'], 'imaginary': weights_imaginary['wh1h2']}, {'real':biases_real['bh1h2'], 'imaginary': biases_imaginary['bh1h2']})\n",
    "    fc2 = nonlinear(fc2)\n",
    "    \n",
    "    fc3 = activation(fc2, {'real':weights_real['wh2h3'], 'imaginary': weights_imaginary['wh2h3']}, {'real':biases_real['bh2h3'], 'imaginary': biases_imaginary['bh2h3']})\n",
    "    fc3 = nonlinear(fc3)\n",
    "    \n",
    "    fc4 = activation(fc3, {'real':weights_real['wh3h4'], 'imaginary': weights_imaginary['wh3h4']}, {'real':biases_real['bh3h4'], 'imaginary': biases_imaginary['bh3h4']})\n",
    "    fc4 = nonlinear(fc4)\n",
    "    \n",
    "    out = activation(fc4, {'real':weights_real['wh4o'], 'imaginary': weights_imaginary['wh4o']}, {'real':biases_real['bh4o'], 'imaginary': biases_imaginary['bh4o']})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = main_network({'real':image_real, 'imaginary': image_imag}, {'real':weights_real, 'imaginary':weights_imaginary}, {'real':biases_real, 'imaginary':biases_imaginary})\n",
    "# prediction = z2class(prediction)\n",
    "\n",
    "# define real and imaginary components of loss function...\n",
    "real_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction['real'], labels = label_real))\n",
    "imaginary_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction['imaginary'], labels = label_imag))\n",
    "\n",
    "#net cost is peoduct of both\n",
    "cost = real_cost * imaginary_cost\n",
    "\n",
    "# optimizer for real and imaginary components of loss function...\n",
    "real_optimizer = tf.train.AdamOptimizer(learning_rate).minimize((real_cost - imaginary_cost))\n",
    "imaginary_optimizer = tf.train.AdamOptimizer(learning_rate).minimize((imaginary_cost + real_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model evaluation correct real and imaginary prediction ..\n",
    "correct_real_prediction = tf.equal(tf.argmax(prediction['real'], 1), tf.argmax(label_real, 1))\n",
    "correct_imaginary_prediction = tf.equal(tf.argmax(prediction['imaginary'], 1), tf.argmax(label_imag, 1))\n",
    "\n",
    "# real and imaginary accuracy components...\n",
    "real_acc = tf.reduce_mean(tf.cast(correct_real_prediction, tf.float32))\n",
    "imag_acc = tf.reduce_mean(tf.cast(correct_imaginary_prediction, tf.float32))\n",
    "\n",
    "# final accuracy is product of both real and imaginary components.. \n",
    "accuracy = real_acc * imag_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all tf variable initialization ...\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f15c57fe2ad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munroll_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass2z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/koriavinash/Documents/MNIST_digit_recognition/input_data.pyc\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, batch_size, fake_data)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_in_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step < epoch * batch_size:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x, batch_y = unroll_image(batch_x), class2z(batch_y)\n",
    "        \n",
    "        sess.run([real_optimizer, imaginary_optimizer], feed_dict={image_real: tf.cast(tf.real(batch_x), dtype=tf.float32), label_real: tf.cast(tf.real(batch_y), dtype = tf.float32), image_imag: tf.cast(tf.imag(batch_x), dtype=tf.float32), label_imag: tf.cast(tf.imag(batch_y), dtype = tf.float32)})\n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={image_real: tf.cast(tf.real(batch_x), dtype=tf.float32), label_real: tf.cast(tf.real(batch_y), dtype = tf.float32), image_imag: tf.cast(tf.imag(batch_x), dtype=tf.float32), label_imag: tf.cast(tf.imag(batch_y), dtype = tf.float32)})\n",
    "            print(\"loss= {:.6f}\".format(loss) + \", Accuracy= {:.5f}\".format(acc))\n",
    "        step += 1\n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    test_images = unroll_image(mnist.test.images[:10])\n",
    "    test_labels = class2z(mnist.test.labels[:10])\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={image_real: tf.cast(tf.real(test_images), dtype=tf.float32), label_real: tf.cast(tf.real(test_labels), dtype = tf.float32), image_imag: tf.cast(tf.imag(test_images), dtype=tf.float32), label_imag: tf.cast(tf.imag(test_labels), dtype = tf.float32)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
