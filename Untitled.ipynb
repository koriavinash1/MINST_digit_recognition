{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training images....\n",
      "extracting training labels....\n",
      "extracting testing images....\n",
      "extracting testing labels....\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import input_data\n",
    "from additional_funcs import pre_processing\n",
    "mnist = input_data.read_data_sets(one_hot=True, train_image_number=60, test_image_number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 784\n",
    "n_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "epochs = 20\n",
    "display_steps = 1\n",
    "test_examples = 10\n",
    "IS_POSITION_BASED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_input = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "image_label = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "if IS_POSITION_BASED:\n",
    "    X_pos = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "    Y_pos = tf.placeholder(tf.float32, [None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784 784\n"
     ]
    }
   ],
   "source": [
    "# some input arrays\n",
    "nx, ny = (28, 28)\n",
    "x = np.linspace(0, 1, nx)\n",
    "y = np.linspace(0, 1, ny)\n",
    "xpos, ypos = np.meshgrid(x, y)\n",
    "xpos = np.array(xpos).flatten()\n",
    "ypos = np.array(ypos).flatten()\n",
    "print len(xpos), len(ypos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_variables(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape = shape))\n",
    "\n",
    "def activation(x, w, b):\n",
    "    return tf.add(tf.matmul(x, w), b)\n",
    "\n",
    "def nonlinear(x):\n",
    "    return tf.sigmoid(x)\n",
    "\n",
    "def conv2d(x, W, b):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wih1_v': define_variables([5, 5, 1, 32]),\n",
    "    'wh1h2': define_variables([5, 5, 32, 64]),\n",
    "    'wh2h3': define_variables([7*7*64, 128]),\n",
    "    'wh3h4': define_variables([128, 1024]),\n",
    "    'out': define_variables([1024, n_classes]),\n",
    "}\n",
    "\n",
    "if IS_POSITION_BASED:\n",
    "    weights['wih1_xpos'] = define_variables([5, 5, 1, 32])\n",
    "    weights['wih1_ypos'] = define_variables([5, 5, 1, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'bih1_v': define_variables([32]),\n",
    "    'bh1h2': define_variables([64]),\n",
    "    'bh2h3': define_variables([128]),\n",
    "    'bh3h4': define_variables([1024]),\n",
    "    'out': define_variables([n_classes]),\n",
    "}\n",
    "\n",
    "if IS_POSITION_BASED:\n",
    "    biases['bih1_xpos'] = define_variables([32])\n",
    "    biases['bih1_ypos'] = define_variables([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_network(x, weights, basies):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    conv1_v = conv2d(x, weights['wih1_v'], biases['bih1_v'])\n",
    "    conv1 = conv1_v\n",
    "    \n",
    "    if IS_POSITION_BASED:\n",
    "        xpos = tf.reshape(X_pos, shape=[-1, 28, 28, 1])\n",
    "        ypos = tf.reshape(Y_pos, shape=[-1, 28, 28, 1])\n",
    "        conv1_xpos = conv2d(xpos, weights['wih1_xpos'], biases['bih1_xpos'])\n",
    "        conv1_ypos = conv2d(ypos, weights['wih1_ypos'], biases['bih1_ypos'])\n",
    "        conv1 = tf.multiply(tf.multiply(conv1_xpos, conv1_ypos), conv1_v)\n",
    "        \n",
    "    pool1 = maxpool2d(conv1)\n",
    "    \n",
    "    conv2 = conv2d(pool1, weights['wh1h2'], biases['bh1h2'])\n",
    "    pool2 = maxpool2d(conv2)\n",
    "    \n",
    "    fc1 = tf.reshape(pool2, [-1, weights['wh2h3'].get_shape().as_list()[0]])\n",
    "    \n",
    "    fc1 = nonlinear(activation(fc1, weights['wh2h3'], biases['bh2h3']))\n",
    "    \n",
    "    fc2 = nonlinear(activation(fc1, weights['wh3h4'], biases['bh3h4']))\n",
    "    \n",
    "    out = nonlinear(activation(fc2, weights['out'], biases['out']))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = main_network(image_input, weights, biases)\n",
    "    \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=image_label))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(image_label,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2352)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 2352) for Tensor u'Placeholder_4:0', which has shape '(?, 784)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9978ec9d0007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    944\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 2352) for Tensor u'Placeholder_4:0', which has shape '(?, 784)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step < epochs * batch_size:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = pre_processing(batch_x)\n",
    "        print batch_x.shape\n",
    "        \n",
    "        if IS_POSITION_BASED:\n",
    "            sess.run(optimizer, feed_dict={image_input: batch_x, image_label: batch_y, X_pos: np.repeat(xpos, batch_size), Y_pos: np.repeat(ypos, batch_size)})\n",
    "        else:\n",
    "            sess.run(optimizer, feed_dict={image_input: batch_x, image_label: batch_y})\n",
    "        \n",
    "        if step % display_steps == 0:\n",
    "            \n",
    "            if IS_POSITION_BASED:\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict={image_input: batch_x, image_label: batch_y, X_pos: xpos, Y_pos: ypos})\n",
    "            else:\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict={image_input: batch_x, image_label: batch_y})\n",
    "                \n",
    "            print(\"loss= {:.6f}\".format(loss) + \", Accuracy= {:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={image_input: pre_processing(mnist.test.images[:test_examples]), image_label: mnist.test.labels[:test_examples]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
